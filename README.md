
# Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility

While synthetic data has proven effective for improving scientific reasoning in the text domain, multimodal reasoning remains constrained by the difficulty of synthesizing scientifically rigorous images. We conduct a systematic study of scientific image synthesis, analyzing both pixel-based generation and programmatic synthesis. We propose **ImgCoder**, a logic-driven framework that follows an explicit *"Understand â†’ Plan â†’ Code"* workflow to improve structural precision . To rigorously assess scientific correctness, we introduce **SciGenBench**, which evaluates generated images based on information utility and logical validity. Finally, we demonstrate that fine-tuning Large Multimodal Models (LMMs) on rigorously verified synthetic scientific images yields consistent reasoning gains. 

---

## ğŸŒŸ Key Contributions

* **ImgCoder Framework**: A logic-driven programmatic framework decoupling reasoning from rendering to achieve state-of-the-art structural precision.


* **SciGenBench**: A large-scale benchmark with **1.4K problems** across **5 domains** (Math, Physics, Chemistry, Biology, Universal) and **25 image types**, utilizing a hybrid evaluation protocol (LMM-as-Judge + Inverse Quiz Validation) .


* **Systematic Analysis**: We reveal a "Precision-Expressiveness" trade-off between pixel-based and code-based paradigms and categorize 5 systematic failure modes.


* **Downstream Utility**: We prove that high-fidelity synthetic data scales multimodal reasoning capabilities, with performance following a log-linear growth trend.

---

## ğŸ“Š SciGenBench: The Benchmark

SciGenBench evaluates scientific image generation on two core dimensions: **Information Utility** (via Inverse Quiz Validation) and **Logical Correctness** (via LMM-as-Judge).

### Taxonomy

The benchmark covers 5 major subjects and 25 fine-grained image types:

* ğŸ§® **Math**: Geometry (Plane/Solid), Analytic, Set & Probability.
* âš›ï¸ **Physics**: Mechanics, Fields, Optics, Circuits, Thermodynamics, etc.
* ğŸ§ª **Chemistry**: Molecular Structures, Crystal Structures, Reaction Schemes.
* ğŸ§¬ **Biology**: Cell Diagrams, Genetics, Ecological, Molecular Processes.
* ğŸ“ˆ **Universal**: Plots, Charts, Graphs, Tables.

### Main Results (Leaderboard)

| Model Type | Model Name |  (%) | Judge Score (C&F) | Judge Score (L&P) |
| --- | --- | --- | --- | --- |
| **Closed Source** | **Nanobanana-Pro** | **73.41** | **1.59** | **1.87** |
|  | GPT-Image-1.5 | 63.52 | 0.98 | 1.70 |
| **ImgCoder** | **Gemini-3-Pro-ImgCoder** | **77.87** | **1.93** | **1.82** |
|  | Qwen3-ImgCoder | 56.38 | 1.21 | 1.30 |
| **Open Source** | Qwen-Image | 38.86 | 0.78 | 0.24 |
|  | HunyuanImage-3.0 | 30.79 | 0.39 | 0.70 |

> Note:  denotes Inverse Validation Rate. C&F = Correctness & Fidelity, L&P = Layout & Precision. See paper for full details.
> 
> 

---

## ğŸš€ ImgCoder: Logic-Driven Synthesis

Unlike pixel-based models that generate images end-to-end, **ImgCoder** adopts a programmatic paradigm:

1. **Understand**: Parses the scientific problem.
2. **Plan**: Explicitly plans image content, layout, labels, and drawing constraints .


3. **Code**: Generates executable code (Python/Matplotlib/TikZ) to render the diagram deterministically.

This approach eliminates hallucinations in structure-heavy tasks (e.g., coordinate systems, circuit topologies).

---

## ğŸ“ˆ Downstream Utility & Scaling

We explored whether synthetic data improves downstream LMM reasoning. The answer is **Yes**.

### Training Performance

We fine-tuned Qwen3-VL-8B using synthetic data from different sources.

* **Result:** Models trained on higher-quality data (e.g., `Nanobanana-Pro`, `Gemini-ImgCoder`) significantly outperform baselines.
* **Scaling:** Performance scales log-linearly with data size without saturation, similar to text-domain scaling laws.

(Figure: Training Reward Curves and Downstream Accuracy. Higher quality generators (Nano-Banana-Pro) yield higher rewards and test accuracy. )

### Evaluation on Benchmarks (GEO3K & MathVision)

| Model Variant | GEO3K | MV | Average |
| --- | --- | --- | --- |
| **Nanobanana-Pro** | **70.7** | 46.1 | **58.4** |
| Nanobanana-Pro (Filt) | 68.7 | **47.7** | 58.2 |
| Gemini-ImgCoder | 69.1 | 46.9 | 58.0 |
| Qwen-Image (Filt) | 68.6 | 47.0 | 57.8 |
| Qwen-Image | 68.2 | 45.9 | 57.1 |
| *Baseline* | *61.9* | *39.0* | *54.5* |

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ data/                 # SciGenBench data and taxonomy
â”œâ”€â”€ infer/                # Source code for image generation
â”œâ”€â”€ evaluation/           # Evaluation scripts
â””â”€â”€ training/             # VeRL-based training scripts

```

---

## ğŸ› ï¸ Usage

### 1. Installation

```bash
git clone https://github.com/your-username/scientific-image-synthesis.git
cd scientific-image-synthesis
pip install -r requirements.txt

```

### 2. Run ImgCoder Generation

```bash
python run_imgcoder.py \
    --input_file data/problems.json \
    --backbone gemini-3-pro \
    --output_dir results/generated_images

```

### 3. Run Evaluation (SciGenBench)

```bash
python eval_scigenbench.py \
    --image_dir results/generated_images \
    --mode all  # Runs both Judge and Inverse Validation

```

---

## ğŸ“ Citation

If you find this work useful, please cite our paper:

```bibtex
@article{anonymous2025scientific,
  title={Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility},
  author={Anonymous Authors},
  journal={Under Review},
  year={2025}
}

```
